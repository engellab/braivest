{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braivest.analysis.wandb_utils import load_wandb_model\n",
    "from braivest.utils import load_data\n",
    "from braivest.model.emgVAE import emgVAE\n",
    "from braivest.preprocess.dataset_utils import bin_data, find_artifacts\n",
    "from braivest.analysis.plotting_utils import *\n",
    "from braivest.analysis.hmm_utils import *\n",
    "\n",
    "import plotly.express as px\n",
    "import wandb\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ssm.hmm import MultiHMM, HMM\n",
    "import ssm\n",
    "from pyvis.network import Network\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with wandb.init(project=\"braivest_tutorial\", job_type=\"download\") as run:\n",
    "    artifact = run.use_artifact(\"analysis_set:v0\")\n",
    "    artifact_dir = artifact.download()\n",
    "subject0_sess = load_data(artifact_dir, 'sess_datas.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =load_wandb_model(\"juliahwang/lfp_VAE/v2l9tltt\", 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with wandb.init(project=\"braivest_tutorial\", job_type=\"download\") as run:\n",
    "    raw_artifact = run.use_artifact(\"raw_data:v0\")\n",
    "    raw_artifact_dir = raw_artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For fitting the HMM, we want datasets that are continuous. So we need to split the data every time there is an artifact.\n",
    "subject0_sessions = [0,2,4,5,6,7,8,9,10,11,12]\n",
    "\n",
    "encodings_all = []\n",
    "\n",
    "for sess in range(1, len(subject0_sessions)):\n",
    "    lfp = load_data(raw_artifact_dir, \"lfp_session{}.npy\".format(0), allow_pickle=True)\n",
    "    artifacts = find_artifacts(lfp)\n",
    "    encodings_full = model.encode(subject0_sess[sess])\n",
    "    encodings_split = np.split(encodings_full, artifacts)\n",
    "    encodings_split_mod = [split[1:] for split in encodings_split if len(split) > 1]\n",
    "    encodings_all.extend(encodings_split_mod)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#We can also load preprovided encodings split by artifact\n",
    "encodings_all = np.load(\"subject0_visual11_encodings.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First use cross validation to find the correct number of clusters\n",
    "scores = []\n",
    "scores_std = []\n",
    "for n_clusters in range(2, 15):\n",
    "    hmm, train_scores, test_scores = hmm_cross_val(n_clusters, encodings_all, n_repeats=3)\n",
    "    scores.append(np.mean(test_scores))\n",
    "    scores_std.append(np.std(test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(range(2, 15),np.asarray(scores)*-1, yerr = scores_std)\n",
    "plt.xlabel(\"Number of Components\")\n",
    "plt.ylabel(\"Negative Log Likelihood\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.asarray(scores)\n",
    "plt.plot(range(3,15),(scores[1:]*-1 - scores[:-1]*-1)/scores[:-1]*-1)\n",
    "plt.xlabel(\"Number of Components\")\n",
    "plt.ylabel(\"Percent change\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm = HMM(8, 2)\n",
    "hmm_lls = hmm.fit(encodings_all, method=\"em\", num_iters=50, init_method=\"kmeans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprovided hmm for consistency\n",
    "hmm = pickle.load(open('subject0_hmm.p', \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_labels = get_hmm_labels(hmm, encodings_all[:100])\n",
    "fig = plot_encodings(np.concatenate(encodings_all[:100], axis=0), color=np.concatenate(sess_labels), x_range = (-6, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend = {0:'SWS1', 1:'AE', 2: 'REM', 3: 'T1', 4: 'SWS2',5:'SWS3', 6:'Wake', 7:'T2'}\n",
    "color_map = {'REM':'#2986cc', \"Wake\":\"#e67f38\", 'AE':'#f44336', \"T1\":\"#d3f758\", 'SWS1':'#93c432','SWS2':'#789837' ,'SWS3':'#38761d', 'T2':'#ecf132'} \n",
    "fig = plot_encodings(np.concatenate(encodings_all[:100], axis=0), color=[legend[l] for l in np.concatenate(sess_labels)], color_map= color_map, x_range = (-6, 3))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_labels = np.concatenate(get_hmm_labels(hmm, encodings_all))\n",
    "colors = [color_map[legend[s]] for s in range(8)]\n",
    "inferred_durations, fig = plot_state_duration(sess_labels, 0, color=colors[0])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_transition_graph(8, hmm.transitions.transition_matrix, sess_labels, colors, \"transition_graph.html\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('bs2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c07403437f230df02b8cc610fa460d9d4449cdd9b5c8c476e92391ae778a8523"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
